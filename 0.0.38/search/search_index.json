{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Get Started","text":"<p>The deepset Cloud SDK is an open source software development kit that provides convenient access and integration with deepset Cloud, a powerful cloud offering for various natural language processing (NLP) tasks. To learn more about deepset Cloud, please have a look at the official Documentation.</p>"},{"location":"#supported-features","title":"Supported Features","text":"<p>The following examples demonstrate how to use the deepset Cloud SDK to interact with deepset Cloud using Python. You can use the deepset Cloud SDK in the command line as well. For more information, see the CLI documentation. - SDK Examples - Upload datasets - CLI Examples - Upload datasets</p>"},{"location":"#installation","title":"Installation","text":"<p>The deepset Cloud SDK is available on PyPI and you can install it using pip: <pre><code>pip install deepset-cloud-sdk\n</code></pre></p> <p>After installing the deepset Cloud SDK, you can use it to interact with deepset Cloud. It comes with a command line interface (CLI), that you can use by calling: <pre><code>deepset-cloud --help\n</code></pre></p> <p> </p>"},{"location":"#development-installation","title":"Development Installation","text":"<p>To install the deepset Cloud SDK for development, clone the repository and install the package in editable mode: <pre><code>pip install hatch==1.7.0\nhatch build\n</code></pre></p> <p>Instead of calling the cli from the build package, you can call it directly from the source code: <pre><code>python3 -m deepset_cloud_sdk.cli --help\n</code></pre></p>"},{"location":"#interested-in-deepset-cloud","title":"Interested in deepset Cloud?","text":"<p>If you are interested in exploring deepset Cloud, visit cloud.deepset.ai. deepset Cloud provides a range of NLP capabilities and services to help you build and deploy powerful natural language processing applications.</p>"},{"location":"#interested-in-haystack","title":"Interested in Haystack?","text":"<p>deepset Cloud is powered by Haystack, an open source framework for building end-to-end NLP pipelines.  - Project website  - GitHub repository</p>"},{"location":"upload_files/","title":"Overview","text":"<p>Uploading with SDK is the fastest way if you have many files. It uses sessions under the hood. That means, you create a session and then upload files to this session. Each session has an ID and you can check its status. The upload starts when you close a session. If you leave a session open, it expires after 24 hours.</p> <p>After your files are uploaded, it can take a while for them to be listed in deepset Cloud. This means that if you deployed a pipeline, you may need to wait a while for it to run on the newly uploaded files.</p> <p>You can use the CLI or the SDK Python methods to upload your files.</p>"},{"location":"upload_files/#folder-structure","title":"Folder Structure","text":"<p>You don't need to follow any specific folder structure. If your folder contains files with the same name, all these files are uploaded, by default. You can set the <code>--write-mode</code> to overwrite the files, keep them all, or fail the upload. For more information, see CLI examples and SDK examples.</p>"},{"location":"upload_files/#upload-files","title":"Upload Files","text":"<p>To upload files:</p> <ol> <li>Log in to the sdk: <code>deepset-cloud login</code> (MacOS and Linux) or <code>python -m deepset_cloud_sdk.cli login</code> (Windows).</li> <li>When prompted, paste your deepset Cloud API key.</li> <li>Type the name of the deepset Cloud workspace you want to set as default for all operations.</li> <li> <p>Choose if you want to use the CLI or a Python script to upload:</p> <ul> <li>To upload files from a folder using CLI, run: <code>deepset-cloud upload &lt;path to the upload folder&gt;</code> (MacOS and Linux) or <code>python -m deepset_cloud_sdk.cli upload &lt;path to the upload folder&gt;</code> (On Windows)</li> <li>To upload files from a folder using a Python script, create the script and run it. Here's an example you can use: </li> </ul> <pre><code>from pathlib import Path\nfrom deepset_cloud_sdk.service.files_service import DeepsetCloudFile\nfrom deepset_cloud_sdk.workflows.sync_client.files import upload\n\n## Uploads all files from a given path\nupload(\npaths=[Path(\"&lt;your_path_to_the_upload_folder&gt;\")],\nblocking=True,  # waits until the files are displayed in deepset Cloud,\n                # this may take a couple of minutes\ntimeout_s=300,  # the timeout for the `blocking` parameter in number of seconds\nshow_progress=True,  # shows the progress bar\nrecursive=True,  # uploads files from all subfolders as well\n)\n</code></pre> </li> </ol> <p>For more examples, see CLI examples and SDK examples.</p>"},{"location":"upload_files/#metadata","title":"Metadata","text":"<p>To add metadata to your files, create one metadata file for each TXT or PDF file you upload. The metadata file must be a JSON with the same name as the file whose metadata it contains and the extension <code>meta.json</code>.</p> <p>For example, if you're uploading a file called <code>example.txt</code>, the metadata file should be called <code>example.txt.meta.json</code>. If you're uploading a file called <code>example.pdf</code>, the metadata file should be <code>example.pdf.meta.json</code>.</p> <p>The format your metadata in your metadata files should follow is: <code>{\"meta_key1\": \"value1\", \"meta_key2\": \"value2\"}</code>. See the example metadata file.</p>"},{"location":"_pydoc/temp/async_client/","title":"Asynchronous Client","text":""},{"location":"_pydoc/temp/async_client/#module-files","title":"Module files","text":"<p>This module contains async functions for uploading files and folders to deepset Cloud.</p> <p></p>"},{"location":"_pydoc/temp/async_client/#list_files","title":"list_files","text":"<pre><code>async def list_files(\n        api_key: Optional[str] = None,\n        api_url: Optional[str] = None,\n        workspace_name: str = DEFAULT_WORKSPACE_NAME,\n        name: Optional[str] = None,\n        content: Optional[str] = None,\n        odata_filter: Optional[str] = None,\n        batch_size: int = 100,\n        timeout_s: Optional[int] = None) -&gt; AsyncGenerator[List[File], None]\n</code></pre> <p>List all files in a workspace.</p> <p>Arguments:</p> <ul> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to list the files from. It uses the workspace from the .ENV file by default.</li> <li><code>name</code>: Name of the file to odata_filter for.</li> <li><code>content</code>: Content of the file to odata_filter for.</li> <li><code>odata_filter</code>: The odata_filter to apply to the file list. For example, <code>odata_filter=\"category eq 'news'\"</code> lists files with metadata <code>{\"meta\": {\"category\": \"news\"}}</code>.</li> <li><code>timeout_s</code>: The timeout in seconds for this API call.</li> <li><code>batch_size</code>: Batch size for the listing.</li> </ul> <p>Returns:</p> <p>List of files.</p> <p></p>"},{"location":"_pydoc/temp/async_client/#list_upload_sessions","title":"list_upload_sessions","text":"<pre><code>async def list_upload_sessions(\n    api_key: Optional[str] = None,\n    api_url: Optional[str] = None,\n    workspace_name: str = DEFAULT_WORKSPACE_NAME,\n    is_expired: Optional[bool] = None,\n    batch_size: int = 100,\n    timeout_s: Optional[int] = None\n) -&gt; AsyncGenerator[List[UploadSessionDetail], None]\n</code></pre> <p>List the details of all upload sessions for a given workspace, including the closed sessions.</p> <p>Arguments:</p> <ul> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to list the files from. It uses the workspace from the .ENV file by default.</li> <li><code>is_expired</code>: Whether to list expired upload sessions.</li> <li><code>batch_size</code>: Batch size for the listing.</li> <li><code>timeout_s</code>: Timeout in seconds for the API requests.</li> </ul> <p>Returns:</p> <p>List of files.</p> <p></p>"},{"location":"_pydoc/temp/async_client/#get_upload_session","title":"get_upload_session","text":"<pre><code>async def get_upload_session(\n        session_id: UUID,\n        api_key: Optional[str] = None,\n        api_url: Optional[str] = None,\n        workspace_name: str = DEFAULT_WORKSPACE_NAME) -&gt; UploadSessionStatus\n</code></pre> <p>Get the status of an upload session.</p> <p>Arguments:</p> <ul> <li><code>session_id</code>: ID of the upload session to get the status for.</li> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to list the files from.</li> </ul> <p>Returns:</p> <p>List of files.</p> <p></p>"},{"location":"_pydoc/temp/async_client/#upload","title":"upload","text":"<pre><code>async def upload(paths: List[Path],\n                 api_key: Optional[str] = None,\n                 api_url: Optional[str] = None,\n                 workspace_name: str = DEFAULT_WORKSPACE_NAME,\n                 write_mode: WriteMode = WriteMode.KEEP,\n                 blocking: bool = True,\n                 timeout_s: Optional[int] = None,\n                 show_progress: bool = True,\n                 recursive: bool = False) -&gt; S3UploadSummary\n</code></pre> <p>Upload a folder to deepset Cloud.</p> <p>Arguments:</p> <ul> <li><code>paths</code>: Path to the folder to upload. If the folder contains unsupported files, they're skipped. during the upload. Supported file formats are TXT and PDF.</li> <li><code>api_key</code>: API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to upload the files to. It uses the workspace from the .ENV file by default.</li> <li><code>write_mode</code>: Specifies what to do when a file with the same name already exists in the workspace. Possible options are: KEEP - uploads the file with the same name and keeps both files in the workspace. OVERWRITE - overwrites the file that is in the workspace. FAIL - fails to upload the file with the same name.</li> <li><code>blocking</code>: Whether to wait for the upload to finish.</li> <li><code>timeout_s</code>: Timeout in seconds for the upload.</li> <li><code>show_progress</code>: Shows the upload progress.</li> <li><code>recursive</code>: Uploads files from subdirectories as well.</li> </ul> <p></p>"},{"location":"_pydoc/temp/async_client/#download","title":"download","text":"<pre><code>async def download(workspace_name: str = DEFAULT_WORKSPACE_NAME,\n                   file_dir: Optional[Union[Path, str]] = None,\n                   name: Optional[str] = None,\n                   content: Optional[str] = None,\n                   odata_filter: Optional[str] = None,\n                   include_meta: bool = True,\n                   batch_size: int = 50,\n                   api_key: Optional[str] = None,\n                   api_url: Optional[str] = None,\n                   show_progress: bool = True,\n                   timeout_s: Optional[int] = None) -&gt; None\n</code></pre> <p>Download a folder to deepset Cloud.</p> <p>Downloads all files from a workspace to a local folder.</p> <p>Arguments:</p> <ul> <li><code>workspace_name</code>: Name of the workspace to upload the files to. It uses the workspace from the .ENV file by default.</li> <li><code>file_dir</code>: Path to the folder to download. If the folder contains unsupported files, they're skipped. during the upload. Supported file formats are TXT and PDF.</li> <li><code>include_meta</code>: Whether to include the file meta in the folder.</li> <li><code>batch_size</code>: Batch size for the listing.</li> <li><code>api_key</code>: API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>show_progress</code>: Shows the upload progress.</li> </ul> <p></p>"},{"location":"_pydoc/temp/async_client/#upload_texts","title":"upload_texts","text":"<pre><code>async def upload_texts(files: List[DeepsetCloudFile],\n                       api_key: Optional[str] = None,\n                       api_url: Optional[str] = None,\n                       workspace_name: str = DEFAULT_WORKSPACE_NAME,\n                       write_mode: WriteMode = WriteMode.KEEP,\n                       blocking: bool = True,\n                       timeout_s: Optional[int] = None,\n                       show_progress: bool = True) -&gt; S3UploadSummary\n</code></pre> <p>Upload raw texts to deepset Cloud.</p> <p>Arguments:</p> <ul> <li><code>files</code>: List of DeepsetCloudFiles to upload.</li> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to upload the files to. It uses the workspace from the .ENV file by default.</li> <li><code>write_mode</code>: Specifies what to do when a file with the same name already exists in the workspace. Possible options are: KEEP - uploads the file with the same name and keeps both files in the workspace. OVERWRITE - overwrites the file that is in the workspace. FAIL - fails to upload the file with the same name.</li> <li><code>blocking</code>: Whether to wait for the files to be listed and displayed in deepset Cloud. This may take a couple of minutes.</li> <li><code>timeout_s</code>: Timeout in seconds for the <code>blocking</code> parameter.</li> <li><code>show_progress</code>: Shows the upload progress.</li> </ul>"},{"location":"_pydoc/temp/cli/","title":"deepset Cloud CLI","text":""},{"location":"_pydoc/temp/cli/#module-cli","title":"Module cli","text":"<p>The CLI for the deepset Cloud SDK.</p> <p></p>"},{"location":"_pydoc/temp/cli/#download","title":"download","text":"<pre><code>@cli_app.command()\ndef download(workspace_name: str = DEFAULT_WORKSPACE_NAME,\n             file_dir: Optional[str] = None,\n             name: Optional[str] = None,\n             content: Optional[str] = None,\n             odata_filter: Optional[str] = None,\n             include_meta: bool = True,\n             batch_size: int = 50,\n             api_key: Optional[str] = None,\n             api_url: Optional[str] = None,\n             show_progress: bool = True) -&gt; None\n</code></pre> <p>Download files from deepset Cloud to your local machine.</p> <p>Arguments:</p> <ul> <li><code>workspace_name</code>: Name of the workspace to download the files from. Uses the workspace from the .ENV file by default.</li> <li><code>file_dir</code>: Path to the folder to download. If the folder contains unsupported files, they're skipped. during the upload. Supported file formats are TXT and PDF.</li> <li><code>name</code>: Name of the file to odata_filter for.</li> <li><code>content</code>: Content of the file to odata_filter for.</li> <li><code>odata_filter</code>: odata_filter to apply to the file list.</li> <li><code>include_meta</code>: Whether to include the file meta in the folder.</li> <li><code>batch_size</code>: Batch size for the listing.</li> <li><code>api_key</code>: API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>show_progress</code>: Shows the upload progress.</li> </ul> <p></p>"},{"location":"_pydoc/temp/cli/#login","title":"login","text":"<pre><code>@cli_app.command()\ndef login() -&gt; None\n</code></pre> <p>Log in to deepset Cloud. This command creates an .ENV file with your deepset Cloud API key and the default workspace used for all operations.</p> <p>Run this command before performing any tasks in deepset Cloud using the SDK or CLI, unless you already created the .ENV file.</p> <p>Example:</p> <p><code>deepset-cloud login</code></p> <p>This prompts you to provide your deepset Cloud API key and workspace name.</p> <p></p>"},{"location":"_pydoc/temp/cli/#logout","title":"logout","text":"<pre><code>@cli_app.command()\ndef logout() -&gt; None\n</code></pre> <p>Log out of deepset Cloud. This command deletes the .ENV file created during login.</p> <p>Example:</p> <p><code>deepset-cloud logout</code></p> <p></p>"},{"location":"_pydoc/temp/cli/#list_files","title":"list_files","text":"<pre><code>@cli_app.command()\ndef list_files(api_key: Optional[str] = None,\n               api_url: Optional[str] = None,\n               content: Optional[str] = None,\n               name: Optional[str] = None,\n               odata_filter: Optional[str] = None,\n               workspace_name: str = DEFAULT_WORKSPACE_NAME,\n               batch_size: int = 10,\n               timeout_s: Optional[int] = None) -&gt; None\n</code></pre> <p>List files that exist in the specified deepset Cloud workspace.</p> <p>Arguments:</p> <ul> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to list the files from. Uses the workspace from the .ENV file by default.</li> <li><code>name</code>: Name of the file to odata_filter for.</li> <li><code>content</code>: Content of the file to odata_filter for.</li> <li><code>odata_filter</code>: odata_filter to apply to the file list.</li> <li><code>batch_size</code>: Batch size to use for the file list.</li> <li><code>timeout_s</code>: The timeout for this request, in seconds. Example: <code>deepset-cloud list-files --batch-size 10</code></li> </ul> <p>Example using an odata filter to show only files whose category is \"news\": <code>deepset-cloud list-files --odata-filter 'category eq \"news\"'</code></p> <p></p>"},{"location":"_pydoc/temp/cli/#list_upload_sessions","title":"list_upload_sessions","text":"<pre><code>@cli_app.command()\ndef list_upload_sessions(api_key: Optional[str] = None,\n                         api_url: Optional[str] = None,\n                         is_expired: Optional[bool] = False,\n                         workspace_name: str = DEFAULT_WORKSPACE_NAME,\n                         batch_size: int = 10,\n                         timeout_s: Optional[int] = None) -&gt; None\n</code></pre> <p>List the details of all upload sessions for the specified workspace, including closed sessions.</p> <p>Arguments:</p> <ul> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to list the files from. Uses the workspace from the .ENV file by default.</li> <li><code>is_expired</code>: Whether to list expired upload sessions.</li> <li><code>batch_size</code>: Batch size to use for the file list.</li> <li><code>timeout_s</code>: Timeout in seconds for the API requests. Example: <code>deepset-cloud list-upload-sessions --workspace-name default</code></li> </ul> <p></p>"},{"location":"_pydoc/temp/cli/#get_upload_session","title":"get_upload_session","text":"<pre><code>@cli_app.command()\ndef get_upload_session(session_id: UUID,\n                       api_key: Optional[str] = None,\n                       api_url: Optional[str] = None,\n                       workspace_name: str = DEFAULT_WORKSPACE_NAME) -&gt; None\n</code></pre> <p>Fetch an upload session from deepset Cloud. This method is useful for checking</p> <p>the status of an upload session after uploading files to deepset Cloud.</p> <p>Arguments:</p> <ul> <li><code>session_id</code>: ID of the upload session whose status you want to check.</li> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace where you upload your files. Uses the workspace from the .ENV file by default. Example: <code>deepset-cloud get-upload-session --workspace-name default</code></li> </ul> <p></p>"},{"location":"_pydoc/temp/cli/#version_callback","title":"version_callback","text":"<pre><code>def version_callback(value: bool) -&gt; None\n</code></pre> <p>Show the SDK version and exit.</p> <p>Arguments:</p> <ul> <li><code>value</code>: Value of the version option. Example: <code>deepset-cloud --version</code></li> </ul> <p></p>"},{"location":"_pydoc/temp/cli/#main","title":"main","text":"<pre><code>@cli_app.callback()\ndef main(_: Optional[bool] = typer.Option(\n    None,\n    \"--version\",\n    callback=version_callback,\n    is_eager=True,\n    help=\"Show the SDK version and exit.\")) -&gt; None\n</code></pre> <p>The CLI for the deepset Cloud SDK.</p> <p></p>"},{"location":"_pydoc/temp/cli/#run_packaged","title":"run_packaged","text":"<pre><code>def run_packaged() -&gt; None\n</code></pre> <p>Run the packaged CLI.</p> <p>This is the entrypoint for the package to enable running the CLI using typer.</p> <p>Example:</p> <p><code>deepset cloud run-packaged</code></p>"},{"location":"_pydoc/temp/sync_client/","title":"Synchronous Client","text":""},{"location":"_pydoc/temp/sync_client/#module-files","title":"Module files","text":"<p>Sync client for files workflow.</p> <p></p>"},{"location":"_pydoc/temp/sync_client/#upload","title":"upload","text":"<pre><code>def upload(paths: List[Path],\n           api_key: Optional[str] = None,\n           api_url: Optional[str] = None,\n           workspace_name: str = DEFAULT_WORKSPACE_NAME,\n           write_mode: WriteMode = WriteMode.KEEP,\n           blocking: bool = True,\n           timeout_s: Optional[int] = None,\n           show_progress: bool = True,\n           recursive: bool = False) -&gt; S3UploadSummary\n</code></pre> <p>Upload a folder to deepset Cloud.</p> <p>Arguments:</p> <ul> <li><code>paths</code>: Path to the folder to upload. If the folder contains unsupported file types, they're skipped. deepset Cloud supports TXT and PDF files.</li> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to upload the files to. It uses the workspace from the .ENV file by default.</li> <li><code>write_mode</code>: The write mode determines how to handle uploading a file if it's already in the workspace. Your options are: keep the file with the same name, make the request fail if a file with the same name already exists, or overwrite the file. If you choose to overwrite, all files with the same name are overwritten.</li> <li><code>blocking</code>: Whether to wait for the files to be uploaded and displayed in deepset Cloud.</li> <li><code>timeout_s</code>: Timeout in seconds for the <code>blocking</code> parameter.</li> <li><code>show_progress</code>: Shows the upload progress.</li> <li><code>recursive</code>: Uploads files from subfolders as well.</li> </ul> <p></p>"},{"location":"_pydoc/temp/sync_client/#download","title":"download","text":"<pre><code>def download(workspace_name: str = DEFAULT_WORKSPACE_NAME,\n             file_dir: Optional[Union[Path, str]] = None,\n             name: Optional[str] = None,\n             content: Optional[str] = None,\n             odata_filter: Optional[str] = None,\n             include_meta: bool = True,\n             batch_size: int = 50,\n             api_key: Optional[str] = None,\n             api_url: Optional[str] = None,\n             show_progress: bool = True,\n             timeout_s: Optional[int] = None) -&gt; None\n</code></pre> <p>Download a folder to deepset Cloud.</p> <p>Downloads all files from a workspace to a local folder.</p> <p>Arguments:</p> <ul> <li><code>workspace_name</code>: Name of the workspace to upload the files to. It uses the workspace from the .ENV file by default.</li> <li><code>file_dir</code>: Path to the folder to download. If the folder contains unsupported files, they're skipped. during the upload. Supported file formats are TXT and PDF.</li> <li><code>include_meta</code>: Whether to include the file meta in the folder.</li> <li><code>batch_size</code>: Batch size for the listing.</li> <li><code>api_key</code>: API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>show_progress</code>: Shows the upload progress.</li> <li><code>timeout_s</code>: Timeout in seconds for the API requests.</li> </ul> <p></p>"},{"location":"_pydoc/temp/sync_client/#upload_texts","title":"upload_texts","text":"<pre><code>def upload_texts(files: List[DeepsetCloudFile],\n                 api_key: Optional[str] = None,\n                 api_url: Optional[str] = None,\n                 workspace_name: str = DEFAULT_WORKSPACE_NAME,\n                 write_mode: WriteMode = WriteMode.KEEP,\n                 blocking: bool = True,\n                 timeout_s: Optional[int] = None,\n                 show_progress: bool = True) -&gt; S3UploadSummary\n</code></pre> <p>Upload texts to deepset Cloud.</p> <p>Arguments:</p> <ul> <li><code>files</code>: List of DeepsetCloudFiles to upload.</li> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to upload the files to. It uses the workspace from the .ENV file by default.</li> <li><code>write_mode</code>: Specifies what to do when a file with the same name already exists in the workspace. Possible options are: KEEP - uploads the file with the same name and keeps both files in the workspace. OVERWRITE - overwrites the file that is in the workspace. FAIL - fails to upload the file with the same name.</li> <li><code>blocking</code>: Whether to wait for the files to be uploaded and listed in deepset Cloud.</li> <li><code>timeout_s</code>: Timeout in seconds for the <code>blocking</code> parameter.</li> <li><code>show_progress</code>: Shows the upload progress.</li> </ul> <p></p>"},{"location":"_pydoc/temp/sync_client/#get_upload_session","title":"get_upload_session","text":"<pre><code>def get_upload_session(\n        session_id: UUID,\n        api_key: Optional[str] = None,\n        api_url: Optional[str] = None,\n        workspace_name: str = DEFAULT_WORKSPACE_NAME) -&gt; UploadSessionStatus\n</code></pre> <p>Get the status of an upload session.</p> <p>Arguments:</p> <ul> <li><code>session_id</code>: ID of the upload session to get the status for.</li> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to upload the files to.</li> </ul> <p></p>"},{"location":"_pydoc/temp/sync_client/#list_files","title":"list_files","text":"<pre><code>def list_files(\n        api_key: Optional[str] = None,\n        api_url: Optional[str] = None,\n        workspace_name: str = DEFAULT_WORKSPACE_NAME,\n        name: Optional[str] = None,\n        content: Optional[str] = None,\n        odata_filter: Optional[str] = None,\n        batch_size: int = 100,\n        timeout_s: Optional[int] = None) -&gt; Generator[List[File], None, None]\n</code></pre> <p>List files in a deepset Cloud workspace.</p> <p>Arguments:</p> <ul> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace to list the files from. It uses the workspace from the .ENV file by default.</li> <li><code>name</code>: Name of the file to odata_filter for.</li> <li><code>content</code>: Content of the file to odata_filter for.</li> <li><code>odata_filter</code>: odata_filter to apply to the file list. For example, <code>odata_filter=\"category eq 'news'\" lists files with metadata</code>{\"meta\": {\"category\": \"news\"}}.</li> <li><code>batch_size</code>: Batch size to use for the file list.</li> <li><code>timeout_s</code>: Timeout in seconds for the API requests.</li> </ul> <p></p>"},{"location":"_pydoc/temp/sync_client/#list_upload_sessions","title":"list_upload_sessions","text":"<pre><code>def list_upload_sessions(\n    api_key: Optional[str] = None,\n    api_url: Optional[str] = None,\n    workspace_name: str = DEFAULT_WORKSPACE_NAME,\n    is_expired: Optional[bool] = False,\n    batch_size: int = 100,\n    timeout_s: Optional[int] = None\n) -&gt; Generator[List[UploadSessionDetail], None, None]\n</code></pre> <p>List the details of all upload sessions, including the closed ones.</p> <p>Arguments:</p> <ul> <li><code>api_key</code>: deepset Cloud API key to use for authentication.</li> <li><code>api_url</code>: API URL to use for authentication.</li> <li><code>workspace_name</code>: Name of the workspace whose sessions you want to list. It uses the workspace from the .ENV file by default.</li> <li><code>is_expired</code>: Lists expired sessions.</li> <li><code>batch_size</code>: Batch size to use for the session list.</li> <li><code>timeout_s</code>: Timeout in seconds for the API request.</li> </ul>"},{"location":"examples/cli/","title":"deepset Cloud CLI","text":"<p>The deepset Cloud CLI is a command-line interface tool that you can use to interact with the deepset Cloud SDK and perform various operations, such as uploading files and folders to your deepset Cloud workspace.</p>"},{"location":"examples/cli/#installation","title":"Installation","text":"<p>To install the deepset Cloud CLI, use <code>pip</code>:</p> <pre><code>pip install deepset-cloud-sdk\n</code></pre>"},{"location":"examples/cli/#configuration","title":"Configuration","text":"<p>Before using the deepset Cloud CLI, log in and provide your credentials. You can do this by running the command:</p> <p>On MacOS and Linux:</p> <p><pre><code>deepset-cloud login\n</code></pre> On Windows:</p> <pre><code>python -m deepset_cloud_sdk.cli login\n</code></pre> <p>This command prompts you to enter your API key and default workspace name. Once you provide these details, the CLI stores your credentials in the <code>~/.deepset-cloud/.env</code> file. This file is used as the default configuration for subsequent CLI commands.</p> <p>Alternatively, to use a different environment file for your configuration, you can create an <code>.env</code> file in the local directory. Additionally, you have the flexibility to provide the credentials directly as command-line arguments or set them programmatically in your code.</p>"},{"location":"examples/cli/#usage","title":"Usage","text":"<p>You can use the deepset Cloud CLI by running the following command:</p> <p>On MacOS and Linux:</p> <pre><code>deepset-cloud &lt;command&gt;\n</code></pre> <p>On Windows:</p> <pre><code>python -m deepset_cloud_sdk.cli &lt;command&gt;\n</code></pre> <p>Replace  with one of the supported commands. To list all available commands, use the <code>--help</code> flag."},{"location":"examples/cli/#example-commands","title":"Example Commands","text":""},{"location":"examples/cli/#upload-files-and-folders","title":"Upload Files and Folders","text":"<p>You don't have to follow any special folder structure. If there are multiple files with the same name in your folder, they're all uploaded by default. You can change this behavior with the <code>--write-mode</code> flag. See the examples below.</p> <p>This command uploads the file example.txt to your deepset Cloud workspace.  On MacOS and Linux:</p> <pre><code>deepset-cloud upload ./examples/data/example.txt\n</code></pre> <p>On Windows:</p> <pre><code>python -m deepset_cloud_sdk.cli upload ./examples/data/example.txt\n</code></pre> <p>This command uploads the entire data folder located in the examples directory to your deepset Cloud workspace. The paths in the examples are relative to the current working directory.</p> <p>On MacOS and Linux:</p> <p><pre><code>deepset-cloud upload ./examples/data\n</code></pre> On Windows: <pre><code>python -m deepset_cloud_sdk.cli upload ./examples/data\n</code></pre> To overwrite existing files in your project, use the <code>--write-mode</code> flag. For example:</p> <p>On MacOS and Linux: <pre><code>deepset-cloud upload ./examples/data --write-mode OVERWRITE\n</code></pre> On Windows: <pre><code>python -m deepset_cloud_sdk.cli upload ./examples/data --write-mode OVERWRITE\n</code></pre> This syncs your local files with the files in your deepset Cloud workspace without having to manually delete the files in your workspace.</p>"},{"location":"examples/cli/#downloading-files-from-deepset-cloud","title":"Downloading Files from deepset Cloud","text":"<p>This command downloads all files from a workspace to a local directory. For example:</p> <p>On MacOS and Linux:</p> <p><pre><code>deepset-cloud download --workspace-name &lt;your-workspace-name&gt;\n</code></pre> On Windows: <pre><code>python -m deepset_cloud_sdk.cli download --workspace-name &lt;your-workspace-name&gt;\n</code></pre></p> <p>To filter for specific files, use the same filters as for listing files.</p>"},{"location":"examples/cli/#list-files","title":"List Files","text":"<p>You can run the <code>list-files</code> operation to search files in your deepset Cloud workspace. For example:</p> <p>On MacOS and Linux: <pre><code>deepset-cloud list-files\n</code></pre> On Windows: <pre><code>python -m deepset_cloud_sdk.cli list-files\n</code></pre> with optional arguments:</p> <pre><code>--name \"&lt;your-file-name&gt;\"  # search by file name\n--content \"content\" # search by file content\n--odata-filter \"key eq 'value'\" # search by odata filter\n</code></pre>"},{"location":"examples/cli/#support","title":"Support","text":"<p>If you encounter issues or have  questions, reach out to our team on Discord.</p> <p>We hope you find the deepset Cloud CLI useful in your projects. Happy coding!</p>"},{"location":"examples/sdk/","title":"Examples","text":""},{"location":"examples/sdk/#upload-files-to-deepset-cloud","title":"Upload files to deepset Cloud","text":"<p>You can upload files in three different ways: 1. Upload multiple files by providing explicit file paths. 2. Upload all files from a folder. 3. Upload raw text.</p> <p>For uploading files from your local machine to deepset Cloud, you can use <code>upload</code>.</p>"},{"location":"examples/sdk/#authentication","title":"Authentication","text":"<p>You will need to either explicitly pass an api_key to the <code>upload</code> function or set the environment variable <code>DEEPSET_CLOUD_API_KEY</code> to your api key. By running <code>deepset-cloud login</code> you can also store your api key globally on your machine. This will allow you to omit the api_key parameter in the following examples.</p>"},{"location":"examples/sdk/#example-1-upload-all-files-from-a-folder","title":"Example 1: Upload all files from a folder","text":"<p>Uploads all files from a folder to the default workspace.</p> <pre><code>upload(\n    # workspace_name=\"my_workspace\",  # optional, by default the environment variable \"DEFAULT_WORKSPACE_NAME\" is used\n    paths=[Path(\"./examples/data\")],\n    blocking=True,  # optional, by default True\n    timeout_s=300,  # optional, by default 300\n    show_progress=True,  # optional, by default True\n    recursive=False,  # optional, by default False\n)\n</code></pre>"},{"location":"examples/sdk/#example-2-upload-raw-texts","title":"Example 2: Upload raw texts","text":"<p>Uploads a list of raw texts to the default workspace. This can be useful if you want to process your text first and later upload the content of the files.</p> <pre><code>upload_texts(\n    # workspace_name=\"my_workspace\",  # optional, by default the environment variable \"DEFAULT_WORKSPACE_NAME\" is used\n    files=[\n        DeepsetCloudFile(\n            name=\"example.txt\",\n            text=\"this is text\",\n            meta={\"key\": \"value\"},  # optional\n        )\n    ],\n    blocking=True,  # optional, by default True\n    timeout_s=300,  # optional, by default 300\n)\n</code></pre>"},{"location":"examples/sdk/#colab-notebook","title":"Colab Notebook","text":"<p>We created this Colab notebook with different upload scenarios that you can test out: Upload files with SDK in Collab.</p>"}]}